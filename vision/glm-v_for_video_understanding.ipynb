{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and narrating a video with ZhipuAI GLM's visual capabilities\n",
    "\n",
    "**This tutorial is available in English and is attached below the Chinese explanation**\n",
    "\n",
    "此代码演示了如何通过视频使用 GLM 的视觉功能。 GLM-4 不直接将视频作为输入，但我们可以使用视觉和新的 128K 上下文窗口来一次性描述整个视频的静态帧。\n",
    "\n",
    "**由于模型对视频理解的能力有待提高，在这个代码中的视频理解的细节程度无法达到较高水平。**\n",
    "\n",
    "This cookbook demonstrates how to use GLM's visual capabilities with a video. GLM-4 doesn't take videos as input directly, but we can use vision and the new 128K context window to describe the static frames of a whole video at once. \n",
    "\n",
    "**Since the model's ability to understand videos needs to be improved, the level of detail of video understanding in this code cannot reach a high level. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:19.444102Z",
     "start_time": "2024-01-23T05:15:19.441033Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"ZHIPUAI_API_KEY\"] = \"your api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:19.781936Z",
     "start_time": "2024-01-23T05:15:19.445518Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import base64\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们使用 OpenCV 从包含熊和河流的自然视频中提取帧。我们将使用此视频作为 GLM 的输入\n",
    "\n",
    "First, we use OpenCV to extract frames from a nature video containing bears and a river. We'll use this video as our input to GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:19.918428Z",
     "start_time": "2024-01-23T05:15:19.782832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 frames read.\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"C:\\Users\\jay\\Documents\\Tencent Files\\19085498\\FileRecv\\刘杰工作室（定）.mp4\")\n",
    "base64Frames = []\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        break\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "video.release()\n",
    "print(len(base64Frames), \"frames read.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示其中视频中的一张图来验证视频读取是否正确\n",
    "\n",
    "Show a picture from the video to verify whether the video reading is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:19.923850Z",
     "start_time": "2024-01-23T05:15:19.919220Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m first_image \u001b[38;5;241m=\u001b[39m Image(data\u001b[38;5;241m=\u001b[39mbase64\u001b[38;5;241m.\u001b[39mb64decode(\u001b[43mbase64Frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m      2\u001b[0m display_handle \u001b[38;5;241m=\u001b[39m display(first_image, display_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "first_image = Image(data=base64.b64decode(base64Frames[100].encode(\"utf-8\")))\n",
    "display_handle = display(first_image, display_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦我们有了视频帧，我们就制作提示并向 GLM 发送请求（请注意，我们不需要发送每一帧让 GLM 了解发生了什么）：\n",
    "\n",
    "Once we have the video frames, we craft our prompt and send a request to GLM (Note that we don't need to send every frame for GLM to understand what's going on):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:19.927577Z",
     "start_time": "2024-01-23T05:15:19.925688Z"
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_MESSAGES = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"这些是我上传的视频的帧。请你根据这些视频祯，进行分析并联系图片的上下文关系，生成引人注目的视频描述。让我们开始吧\"\n",
    "        },\n",
    "        *[\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": frame\n",
    "                }\n",
    "            } for frame in base64Frames[0::50]\n",
    "        ]\n",
    "    ]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T05:15:23.904018Z",
     "start_time": "2024-01-23T05:15:19.929580Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在宁静的河流中，一只雄伟的棕熊正在捕捉它的猎物。这只熊拥有强壮的身体和锋利的爪子，它站在水中，目光专注地盯着前方。突然，它发现了什么有趣的东西，转过头去看向河岸边。几只海鸥正在河岸上站着，它们似乎没有受到熊的存在的影响。然而，当熊靠近它们时，这些鸟儿惊恐地飞走了。这一幕展示了大自然中的生存法则，无论是熊还是海鸥，都必须时刻警惕着捕食者和被捕食者的威胁。在这个世界中，每个生物都有自己的角色和使命，而这一切都离不开生态平衡的维持。\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"model\": \"glm-4v\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"max_tokens\": 20000,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 1,\n",
    "}\n",
    "\n",
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
